
{
  "name": "llama150m",
  "n_embd": 1024,
  "intermediate_size": 4096,
  "n_head": 16,
  "n_layer": 12,
  "vocab_size": 32000,
  "block_size": 1024
}